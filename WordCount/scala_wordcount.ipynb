{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948598dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a3de3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "val sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ffe09cc-a6f0-4f09-94a9-3a3779ab3d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text = input/text1.txt MapPartitionsRDD[30] at textFile at <console>:26\n",
       "counts = ShuffledRDD[34] at reduceByKey at <console>:32\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array((d,29593), (z,72), (\",347), (4,42), (8,13), (p,27557), (x,15), (6,22), (t,123248), (.,56), (0,1), (b,45409), (h,60538), (2,93), (>,1), (n,26707), (*,16), (f,36682), (j,3339), (v,5712), ((,628), (&,21), (<,248), (r,14178), (l,29502), (:,1), (',3803), (s,65609), (e,18608), (/,1), (w,59402), (7,17), (5,30), (a,84502), (_,1), (i,62006), (k,9413), (y,25781), (u,9114), (},2), (#,1), (o,43243), (9,14), (3,56), (],7), (q,2377), (-,45), (?,2), (1,418), (g,20699), ([,2082), (m,55625), (c,34431))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val text = sc.textFile(\"input/text1.txt\"); //sc stands for spark context \n",
    "//We split the input as llines and each line is split into words. \n",
    "//Each word is used as a key and a value of 1 is assigned to it. \n",
    "//The reduce by key adds all the values for a given key \n",
    "val counts = text.flatMap(line => line.toLowerCase().split(\" \"))\n",
    ".filter(word => word.length() >= 1)\n",
    ".map(word => (word.substring(0,1),1)).reduceByKey(_+_); \n",
    "//Result will be saved in the folder “wordcount Scala output”. \n",
    "//The result will be in a textfile named part-00000 \n",
    "counts.coalesce(1, shuffle=true).saveAsTextFile(\"wordcount Scala output\") \n",
    "// This is used to display the result on the notebook\n",
    "counts.collect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04bf8c08-12a9-4564-b25c-78bbd9e76119",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8252dd74-b774-449e-a78a-e930a9b45e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark in Scala - Apache Toree",
   "language": "scala",
   "name": "apache_toree_scala2"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
